{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfaffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yiweihan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yiweihan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yiweihan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for text pre-processing\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "#for model-building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#for word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7863d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('congressional_tweet_training_data.csv')\n",
    "df_test=pd.read_csv('congressional_tweet_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a90870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D    324202\n",
      "R    268601\n",
      "Name: party_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x=df_train['party_id'].value_counts()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3002d869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "favorite_count        0\n",
       "full_text             0\n",
       "hashtags              0\n",
       "retweet_count         0\n",
       "year              18712\n",
       "party_id              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085bfcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.86333260114445\n",
      "26.960345710390435\n"
     ]
    }
   ],
   "source": [
    "df_train['word_count'] = df_train['full_text'].apply(lambda x: len(str(x).split()))\n",
    "print(df_train[df_train['party_id']=='R']['word_count'].mean()) \n",
    "print(df_train[df_train['party_id']=='D']['word_count'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08629eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.91757662853078\n",
      "197.6636356345735\n"
     ]
    }
   ],
   "source": [
    "df_train['char_count'] = df_train['full_text'].apply(lambda x: len(str(x)))\n",
    "print(df_train[df_train['party_id']=='R']['char_count'].mean()) \n",
    "print(df_train[df_train['party_id']=='D']['char_count'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56988b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text\n",
    "\n",
    " \n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ea664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train.full_text.to_list()\n",
    "text_cleaned_train = []\n",
    "for text in df_train['full_text']:\n",
    "    text_cleaned_train.append(finalpreprocess(text))\n",
    "df_train['TextClean'] = text_cleaned_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a447d4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>TextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>24</td>\n",
       "      <td>154</td>\n",
       "      <td>rt kusinews one longtime viewer congressman d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>R</td>\n",
       "      <td>44</td>\n",
       "      <td>317</td>\n",
       "      <td>today urge cdcgov immediately launch phone ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>R</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>tomorrow mo senior graduate calvary lutheran ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>R</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>congrats teamusa canton native jgreenway win ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>39</td>\n",
       "      <td>316</td>\n",
       "      <td>pleased support amergateways june fiesta hono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year party_id  word_count  \\\n",
       "0                    KUSI             10  2017.0        R          24   \n",
       "1             Coronavirus            111  2020.0        R          44   \n",
       "2                    MO03              2  2014.0        R          21   \n",
       "3    TeamUSA WorldJuniors              3  2017.0        R          16   \n",
       "4  ImmigrantHeritageMonth              3  2019.0        D          39   \n",
       "\n",
       "   char_count                                          TextClean  \n",
       "0         154   rt kusinews one longtime viewer congressman d...  \n",
       "1         317   today urge cdcgov immediately launch phone ho...  \n",
       "2         140   tomorrow mo senior graduate calvary lutheran ...  \n",
       "3         130   congrats teamusa canton native jgreenway win ...  \n",
       "4         316   pleased support amergateways june fiesta hono...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = []\n",
    "for i in range(len(df_train['TextClean'])):\n",
    "    text_train.append(df_train['TextClean'].iloc[i][1:])\n",
    "df_train['TextClean'] = text_train\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ab0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df_train['party_id'] = encoder.fit_transform(df_train[\"party_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85bc5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>TextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>154</td>\n",
       "      <td>rt kusinews one longtime viewer congressman d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>317</td>\n",
       "      <td>today urge cdcgov immediately launch phone ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>tomorrow mo senior graduate calvary lutheran ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>congrats teamusa canton native jgreenway win ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>316</td>\n",
       "      <td>pleased support amergateways june fiesta hono...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count    year  party_id  word_count  \\\n",
       "0                    KUSI             10  2017.0         1          24   \n",
       "1             Coronavirus            111  2020.0         1          44   \n",
       "2                    MO03              2  2014.0         1          21   \n",
       "3    TeamUSA WorldJuniors              3  2017.0         1          16   \n",
       "4  ImmigrantHeritageMonth              3  2019.0         0          39   \n",
       "\n",
       "   char_count                                          TextClean  \n",
       "0         154   rt kusinews one longtime viewer congressman d...  \n",
       "1         317   today urge cdcgov immediately launch phone ho...  \n",
       "2         140   tomorrow mo senior graduate calvary lutheran ...  \n",
       "3         130   congrats teamusa canton native jgreenway win ...  \n",
       "4         316   pleased support amergateways june fiesta hono...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1030e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TextHashtag'] = df_train['TextClean']+ ' ' + 2 * df_train['hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22a9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.full_text.to_list()\n",
    "text_cleaned_test = []\n",
    "for text in df_test['full_text']:\n",
    "    text_cleaned_test.append(finalpreprocess(text))\n",
    "df_test['TextClean'] = text_cleaned_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551b5fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>TextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>b'#TaxReform improved the playing field for Am...</td>\n",
       "      <td>TaxReform</td>\n",
       "      <td>13</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>taxreform improve playing field american work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>b'This #NativeWomensEqualPay Day, we recommit ...</td>\n",
       "      <td>NativeWomensEqualPay</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>nativewomensequalpay day recommit pass payche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>b\"\\xe2\\x80\\x9cI became convinced that our gene...</td>\n",
       "      <td>MeToo ShatteringTheSilence</td>\n",
       "      <td>24</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>D</td>\n",
       "      <td>xe x x ci become convinced generation silence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>b'During #NationalAdoptionMonth, we honor the ...</td>\n",
       "      <td>NationalAdoptionMonth</td>\n",
       "      <td>2</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>D</td>\n",
       "      <td>nationaladoptionmonth honor adoptive parent p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>b'Happy #AirborneDay to our @USArmy paratroope...</td>\n",
       "      <td>AirborneDay AirborneAllTheWay</td>\n",
       "      <td>7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>D</td>\n",
       "      <td>happy airborneday usarmy paratrooper veteran ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  favorite_count                                          full_text  \\\n",
       "0   0              70  b'#TaxReform improved the playing field for Am...   \n",
       "1   1              27  b'This #NativeWomensEqualPay Day, we recommit ...   \n",
       "2   2              49  b\"\\xe2\\x80\\x9cI became convinced that our gene...   \n",
       "3   3              14  b'During #NationalAdoptionMonth, we honor the ...   \n",
       "4   4              13  b'Happy #AirborneDay to our @USArmy paratroope...   \n",
       "\n",
       "                        hashtags  retweet_count    year party  \\\n",
       "0                      TaxReform             13  2018.0     D   \n",
       "1           NativeWomensEqualPay             11     NaN     D   \n",
       "2     MeToo ShatteringTheSilence             24  2017.0     D   \n",
       "3          NationalAdoptionMonth              2  2019.0     D   \n",
       "4  AirborneDay AirborneAllTheWay              7  2018.0     D   \n",
       "\n",
       "                                           TextClean  \n",
       "0   taxreform improve playing field american work...  \n",
       "1   nativewomensequalpay day recommit pass payche...  \n",
       "2   xe x x ci become convinced generation silence...  \n",
       "3   nationaladoptionmonth honor adoptive parent p...  \n",
       "4   happy airborneday usarmy paratrooper veteran ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = []\n",
    "for i in range(len(df_test['TextClean'])):\n",
    "    text_test.append(df_test['TextClean'].iloc[i][1:])\n",
    "df_test['TextClean'] = text_test\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62436a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['party'] = encoder.fit_transform(df_test[\"party\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9823ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['TextHashtag'] = df_test['TextClean']+ ' ' + 2 * df_test['hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21511a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tv12 = TfidfVectorizer(lowercase=True, ngram_range=(1,2),min_df=2)\n",
    "X_tv_train = tv12.fit_transform(df_train['TextHashtag'])\n",
    "y_train = df_train.party_id.tolist()\n",
    "X_tv_test = tv12.transform(df_test['TextHashtag'])\n",
    "y_test = df_test.party.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d81e24a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiweihan/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=2, max_iter=200, n_jobs=-1, random_state=265)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lf = LogisticRegressionCV(cv = 2, random_state = 265, max_iter = 200, n_jobs = -1)\n",
    "lf.fit(X_tv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f8c1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = lf.predict(X_tv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26be0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df335f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Id']=range(0,len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "570105ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   party  Id\n",
       "0      1   0\n",
       "1      0   1\n",
       "2      0   2\n",
       "3      1   3\n",
       "4      1   4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.rename(columns={0:'party'})\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfccd957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  party\n",
       "0   0      1\n",
       "1   1      0\n",
       "2   2      0\n",
       "3   3      1\n",
       "4   4      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Idd = final_df['Id']\n",
    "final_df = final_df.drop('Id',axis =1)\n",
    "final_df.insert(0,'Id',Idd)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a241b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_c(x):\n",
    "    if x == 1: \n",
    "        return 'R'\n",
    "    else: \n",
    "        return 'D'\n",
    "final_df['party']=final_df['party'].apply(lambda x: fun_c(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efcab52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id party\n",
       "0   0     R\n",
       "1   1     D\n",
       "2   2     D\n",
       "3   3     R\n",
       "4   4     R"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2263bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('/Users/yiweihan/Desktop/sample_submission20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba098b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also tried several models below, and the best is logisticregressioncv\n",
    "\n",
    "#from sklearn.linear_model import RidgeClassifier\n",
    "#rc=RidgeClassifier()\n",
    "\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#nb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de0e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see how it works when cleaning the hashtags, but after cleaning and merge, we found out useing\n",
    "#cleaned_full_text and not cleaned hashtags are better\n",
    "#ht_train = df_train.hashtags.to_list()\n",
    "#ht_test = df_test.hashtags.to_list()\n",
    "#text_cleaned_train_ht = []\n",
    "#for text in df_train['hashtags']:\n",
    "    #text_cleaned_train_ht.append(clean_text(text))\n",
    "#df_train['Text_HT'] = text_cleaned_train_ht\n",
    "#text_cleaned_test_ht = []\n",
    "#for text in df_test['hashtags']:\n",
    "    #text_cleaned_test_ht.append(clean_text(text))\n",
    "#df_test['Text_HT'] = text_cleaned_test_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tried several parameter, including cv and tv from ngram(1,1) to (1,3)\n",
    "#we found out tv(1,2) with min_df=2 is the best\n",
    "\n",
    "#cv11 = CountVectorizer(lowercase=True,ngram_range=(1,1),min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we merge cleaned text and hashtag togeter, because they are both text\n",
    "#and hashtags are shorter and more important and clearer, so we gave the weight to 2\n",
    "#we also tried 3, but the result did not change much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
